{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[{"sourceId":8514868,"sourceType":"datasetVersion","datasetId":5007013}],"dockerImageVersionId":30699,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"!pip install chess pandarallel","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2024-05-26T10:09:50.280293Z","iopub.execute_input":"2024-05-26T10:09:50.281131Z","iopub.status.idle":"2024-05-26T10:10:06.100662Z","shell.execute_reply.started":"2024-05-26T10:09:50.281100Z","shell.execute_reply":"2024-05-26T10:10:06.099624Z"},"trusted":true},"execution_count":2,"outputs":[{"name":"stdout","text":"Collecting chess\n  Downloading chess-1.10.0-py3-none-any.whl.metadata (19 kB)\nCollecting pandarallel\n  Downloading pandarallel-1.6.5.tar.gz (14 kB)\n  Preparing metadata (setup.py) ... \u001b[?25ldone\n\u001b[?25hRequirement already satisfied: dill>=0.3.1 in /opt/conda/lib/python3.10/site-packages (from pandarallel) (0.3.8)\nRequirement already satisfied: pandas>=1 in /opt/conda/lib/python3.10/site-packages (from pandarallel) (2.1.4)\nRequirement already satisfied: psutil in /opt/conda/lib/python3.10/site-packages (from pandarallel) (5.9.3)\nRequirement already satisfied: numpy<2,>=1.22.4 in /opt/conda/lib/python3.10/site-packages (from pandas>=1->pandarallel) (1.26.4)\nRequirement already satisfied: python-dateutil>=2.8.2 in /opt/conda/lib/python3.10/site-packages (from pandas>=1->pandarallel) (2.9.0.post0)\nRequirement already satisfied: pytz>=2020.1 in /opt/conda/lib/python3.10/site-packages (from pandas>=1->pandarallel) (2023.3.post1)\nRequirement already satisfied: tzdata>=2022.1 in /opt/conda/lib/python3.10/site-packages (from pandas>=1->pandarallel) (2023.4)\nRequirement already satisfied: six>=1.5 in /opt/conda/lib/python3.10/site-packages (from python-dateutil>=2.8.2->pandas>=1->pandarallel) (1.16.0)\nDownloading chess-1.10.0-py3-none-any.whl (154 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m154.4/154.4 kB\u001b[0m \u001b[31m7.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hBuilding wheels for collected packages: pandarallel\n  Building wheel for pandarallel (setup.py) ... \u001b[?25ldone\n\u001b[?25h  Created wheel for pandarallel: filename=pandarallel-1.6.5-py3-none-any.whl size=16672 sha256=f7b387cb86f4305fa59210f96a9aeb775a5c24a5e6f6e4b0e6bec55db876583d\n  Stored in directory: /root/.cache/pip/wheels/50/4f/1e/34e057bb868842209f1623f195b74fd7eda229308a7352d47f\nSuccessfully built pandarallel\nInstalling collected packages: chess, pandarallel\nSuccessfully installed chess-1.10.0 pandarallel-1.6.5\n","output_type":"stream"}]},{"cell_type":"code","source":"import numpy as np\nimport pandas as pd\nimport re\nimport matplotlib.pyplot as plt\nimport random\nfrom tqdm import tqdm\nfrom pandarallel import pandarallel\nfrom multiprocessing import Pool\nimport torch\nfrom torch.utils.data import Dataset, DataLoader\nimport torch.nn as nn\nimport torch.optim as optim\nimport chess\nimport time \n\nrandom.seed(42)\nnp.random.seed(42)","metadata":{"execution":{"iopub.status.busy":"2024-05-26T10:10:06.102625Z","iopub.execute_input":"2024-05-26T10:10:06.102934Z","iopub.status.idle":"2024-05-26T10:10:09.283725Z","shell.execute_reply.started":"2024-05-26T10:10:06.102902Z","shell.execute_reply":"2024-05-26T10:10:09.282934Z"},"trusted":true},"execution_count":3,"outputs":[]},{"cell_type":"code","source":"values = {\n    \"P\": 1,\n    \"R\": 5,\n    \"B\": 3,\n    \"N\": 3,\n    \"K\": 0,\n    \"Q\": 9,\n    \"p\": -1,\n    \"r\": -5,\n    \"b\": -3,\n    \"n\": -3,\n    \"k\": 0,\n    \"q\": -9\n}\n\ndef tan_eval_categories(evaluation):\n    if evaluation < -.5:\n        return 0\n    if evaluation > .5:\n        return 1\n    return 2\n\ndef eval_to_int(evaluation):\n    return int(evaluation) / 100","metadata":{"execution":{"iopub.status.busy":"2024-05-26T10:10:09.284746Z","iopub.execute_input":"2024-05-26T10:10:09.285143Z","iopub.status.idle":"2024-05-26T10:10:09.291335Z","shell.execute_reply.started":"2024-05-26T10:10:09.285119Z","shell.execute_reply":"2024-05-26T10:10:09.290412Z"},"trusted":true},"execution_count":4,"outputs":[]},{"cell_type":"code","source":"tqdm.pandas()\npandarallel.initialize(progress_bar=True)","metadata":{"execution":{"iopub.status.busy":"2024-05-25T13:52:30.356926Z","iopub.execute_input":"2024-05-25T13:52:30.357770Z","iopub.status.idle":"2024-05-25T13:52:30.365685Z","shell.execute_reply.started":"2024-05-25T13:52:30.357739Z","shell.execute_reply":"2024-05-25T13:52:30.364628Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df = pd.read_csv(\"/kaggle/input/no-check-mate-fen/final_data.csv\")","metadata":{"execution":{"iopub.status.busy":"2024-05-25T13:53:12.809250Z","iopub.execute_input":"2024-05-25T13:53:12.809596Z","iopub.status.idle":"2024-05-25T13:53:27.046753Z","shell.execute_reply.started":"2024-05-25T13:53:12.809569Z","shell.execute_reply":"2024-05-25T13:53:27.045982Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"count_pieces = lambda fen, pat=re.compile(r\"[a-zA-Z]\"): len(re.findall(pat, fen.split(' ')[0]))\ntransform_eval = lambda x: np.arctan(x / 3)\nuntransform_eval = lambda x: 3 * np.tan(x)","metadata":{"execution":{"iopub.status.busy":"2024-05-25T13:53:33.439302Z","iopub.execute_input":"2024-05-25T13:53:33.440043Z","iopub.status.idle":"2024-05-25T13:53:33.446838Z","shell.execute_reply.started":"2024-05-25T13:53:33.440013Z","shell.execute_reply":"2024-05-25T13:53:33.445984Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df[\"Pieces\"] = df[\"FEN\"].parallel_map(count_pieces)\ndf[\"Evaluation\"] = df[\"Evaluation\"].parallel_map(eval_to_int)\ndf[\"Normalized Evaluation\"] = transform_eval(df[\"Evaluation\"])\ndf[\"Normalized WLD\"] = df[\"Normalized Evaluation\"].parallel_map(tan_eval_categories)","metadata":{"execution":{"iopub.status.busy":"2024-05-25T13:53:35.488475Z","iopub.execute_input":"2024-05-25T13:53:35.488797Z","iopub.status.idle":"2024-05-25T13:54:46.542834Z","shell.execute_reply.started":"2024-05-25T13:53:35.488773Z","shell.execute_reply":"2024-05-25T13:54:46.541959Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"piece_to_layer = {\n        'R': 1,\n        'N': 2,\n        'B': 3,\n        'Q': 4,\n        'K': 5,\n        'P': 6,\n        'p': 7,\n        'k': 8,\n        'q': 9,\n        'b': 10,\n        'n': 11,\n        'r': 12\n}","metadata":{"execution":{"iopub.status.busy":"2024-05-26T10:10:19.170168Z","iopub.execute_input":"2024-05-26T10:10:19.170819Z","iopub.status.idle":"2024-05-26T10:10:19.175768Z","shell.execute_reply.started":"2024-05-26T10:10:19.170786Z","shell.execute_reply":"2024-05-26T10:10:19.174735Z"},"trusted":true},"execution_count":6,"outputs":[]},{"cell_type":"code","source":"def to_bitboard(fen):\n    boards = np.zeros((29, 8, 8), dtype=np.uint8)\n    board = chess.Board(fen)\n    color = bool(board.turn)\n    cr = board.castling_rights\n    wkcastle = bool(cr & chess.BB_H1)\n    wqcastle = bool(cr & chess.BB_A1)\n    bkcastle = bool(cr & chess.BB_H8)\n    bqcastle = bool(cr & chess.BB_A8)\n\n    boards[0, :, :]  = color\n    boards[25, :, :] = wkcastle\n    boards[26, :, :] = wqcastle\n    boards[27, :, :] = bkcastle\n    boards[28, :, :] = bqcastle\n\n    piece_map = board.piece_map()\n    for i, p in piece_map.items():\n        rank, file = to_square(i)\n        piece = p.symbol()\n        boards[piece_to_layer[piece], rank, file] = 1\n        for sq in board.attacks(i):\n            attack_rank, attack_file = to_square(sq)\n            boards[piece_to_layer[piece] + 12, attack_rank, attack_file] = 1\n    return boards\n\ndef to_square(number):\n    rank, file = divmod(number, 8)\n    return 7 - rank, file\n\n# In bitboard\ndef print_bitboard(boards):\n    np.set_printoptions(linewidth=150)\n    for i in range(boards.shape[0]):\n        print(f\"Layer {i}:\")\n        print(boards[i])\n        print(\"\\n\")\n\nprint_bitboard(to_bitboard(\"r3k2r/p1ppqpb1/bn2pnp1/3PN3/1p2P3/2N2Q1p/PPPBBPPP/R3K2R w KQkq - 0 1\"))","metadata":{"execution":{"iopub.status.busy":"2024-05-26T11:56:10.220842Z","iopub.execute_input":"2024-05-26T11:56:10.221192Z","iopub.status.idle":"2024-05-26T11:56:10.242399Z","shell.execute_reply.started":"2024-05-26T11:56:10.221165Z","shell.execute_reply":"2024-05-26T11:56:10.241403Z"},"trusted":true},"execution_count":25,"outputs":[{"name":"stdout","text":"Layer 0:\n[[1 1 1 1 1 1 1 1]\n [1 1 1 1 1 1 1 1]\n [1 1 1 1 1 1 1 1]\n [1 1 1 1 1 1 1 1]\n [1 1 1 1 1 1 1 1]\n [1 1 1 1 1 1 1 1]\n [1 1 1 1 1 1 1 1]\n [1 1 1 1 1 1 1 1]]\n\n\nLayer 1:\n[[0 0 0 0 0 0 0 0]\n [0 0 0 0 0 0 0 0]\n [0 0 0 0 0 0 0 0]\n [0 0 0 0 0 0 0 0]\n [0 0 0 0 0 0 0 0]\n [0 0 0 0 0 0 0 0]\n [0 0 0 0 0 0 0 0]\n [1 0 0 0 0 0 0 1]]\n\n\nLayer 2:\n[[0 0 0 0 0 0 0 0]\n [0 0 0 0 0 0 0 0]\n [0 0 0 0 0 0 0 0]\n [0 0 0 0 1 0 0 0]\n [0 0 0 0 0 0 0 0]\n [0 0 1 0 0 0 0 0]\n [0 0 0 0 0 0 0 0]\n [0 0 0 0 0 0 0 0]]\n\n\nLayer 3:\n[[0 0 0 0 0 0 0 0]\n [0 0 0 0 0 0 0 0]\n [0 0 0 0 0 0 0 0]\n [0 0 0 0 0 0 0 0]\n [0 0 0 0 0 0 0 0]\n [0 0 0 0 0 0 0 0]\n [0 0 0 1 1 0 0 0]\n [0 0 0 0 0 0 0 0]]\n\n\nLayer 4:\n[[0 0 0 0 0 0 0 0]\n [0 0 0 0 0 0 0 0]\n [0 0 0 0 0 0 0 0]\n [0 0 0 0 0 0 0 0]\n [0 0 0 0 0 0 0 0]\n [0 0 0 0 0 1 0 0]\n [0 0 0 0 0 0 0 0]\n [0 0 0 0 0 0 0 0]]\n\n\nLayer 5:\n[[0 0 0 0 0 0 0 0]\n [0 0 0 0 0 0 0 0]\n [0 0 0 0 0 0 0 0]\n [0 0 0 0 0 0 0 0]\n [0 0 0 0 0 0 0 0]\n [0 0 0 0 0 0 0 0]\n [0 0 0 0 0 0 0 0]\n [0 0 0 0 1 0 0 0]]\n\n\nLayer 6:\n[[0 0 0 0 0 0 0 0]\n [0 0 0 0 0 0 0 0]\n [0 0 0 0 0 0 0 0]\n [0 0 0 1 0 0 0 0]\n [0 0 0 0 1 0 0 0]\n [0 0 0 0 0 0 0 0]\n [1 1 1 0 0 1 1 1]\n [0 0 0 0 0 0 0 0]]\n\n\nLayer 7:\n[[0 0 0 0 0 0 0 0]\n [1 0 1 1 0 1 0 0]\n [0 0 0 0 1 0 1 0]\n [0 0 0 0 0 0 0 0]\n [0 1 0 0 0 0 0 0]\n [0 0 0 0 0 0 0 1]\n [0 0 0 0 0 0 0 0]\n [0 0 0 0 0 0 0 0]]\n\n\nLayer 8:\n[[0 0 0 0 1 0 0 0]\n [0 0 0 0 0 0 0 0]\n [0 0 0 0 0 0 0 0]\n [0 0 0 0 0 0 0 0]\n [0 0 0 0 0 0 0 0]\n [0 0 0 0 0 0 0 0]\n [0 0 0 0 0 0 0 0]\n [0 0 0 0 0 0 0 0]]\n\n\nLayer 9:\n[[0 0 0 0 0 0 0 0]\n [0 0 0 0 1 0 0 0]\n [0 0 0 0 0 0 0 0]\n [0 0 0 0 0 0 0 0]\n [0 0 0 0 0 0 0 0]\n [0 0 0 0 0 0 0 0]\n [0 0 0 0 0 0 0 0]\n [0 0 0 0 0 0 0 0]]\n\n\nLayer 10:\n[[0 0 0 0 0 0 0 0]\n [0 0 0 0 0 0 1 0]\n [1 0 0 0 0 0 0 0]\n [0 0 0 0 0 0 0 0]\n [0 0 0 0 0 0 0 0]\n [0 0 0 0 0 0 0 0]\n [0 0 0 0 0 0 0 0]\n [0 0 0 0 0 0 0 0]]\n\n\nLayer 11:\n[[0 0 0 0 0 0 0 0]\n [0 0 0 0 0 0 0 0]\n [0 1 0 0 0 1 0 0]\n [0 0 0 0 0 0 0 0]\n [0 0 0 0 0 0 0 0]\n [0 0 0 0 0 0 0 0]\n [0 0 0 0 0 0 0 0]\n [0 0 0 0 0 0 0 0]]\n\n\nLayer 12:\n[[1 0 0 0 0 0 0 1]\n [0 0 0 0 0 0 0 0]\n [0 0 0 0 0 0 0 0]\n [0 0 0 0 0 0 0 0]\n [0 0 0 0 0 0 0 0]\n [0 0 0 0 0 0 0 0]\n [0 0 0 0 0 0 0 0]\n [0 0 0 0 0 0 0 0]]\n\n\nLayer 13:\n[[0 0 0 0 0 0 0 0]\n [0 0 0 0 0 0 0 0]\n [0 0 0 0 0 0 0 0]\n [0 0 0 0 0 0 0 0]\n [0 0 0 0 0 0 0 0]\n [0 0 0 0 0 0 0 0]\n [1 0 0 0 0 0 0 1]\n [0 1 1 1 1 1 1 0]]\n\n\nLayer 14:\n[[0 0 0 0 0 0 0 0]\n [0 0 0 1 0 1 0 0]\n [0 0 1 0 0 0 1 0]\n [0 1 0 1 0 0 0 0]\n [1 0 1 0 1 0 1 0]\n [0 0 0 1 0 1 0 0]\n [1 0 0 0 1 0 0 0]\n [0 1 0 1 0 0 0 0]]\n\n\nLayer 15:\n[[0 0 0 0 0 0 0 0]\n [0 0 0 0 0 0 0 0]\n [1 0 0 0 0 0 0 1]\n [0 1 0 0 0 0 1 0]\n [0 0 1 0 0 1 0 0]\n [0 0 1 1 1 1 0 0]\n [0 0 0 0 0 0 0 0]\n [0 0 1 1 1 1 0 0]]\n\n\nLayer 16:\n[[0 0 0 0 0 0 0 0]\n [0 0 0 0 0 0 0 0]\n [0 0 0 0 0 1 0 0]\n [0 0 0 0 0 1 0 1]\n [0 0 0 0 1 1 1 0]\n [0 0 1 1 1 0 1 1]\n [0 0 0 0 1 1 1 0]\n [0 0 0 0 0 0 0 0]]\n\n\nLayer 17:\n[[0 0 0 0 0 0 0 0]\n [0 0 0 0 0 0 0 0]\n [0 0 0 0 0 0 0 0]\n [0 0 0 0 0 0 0 0]\n [0 0 0 0 0 0 0 0]\n [0 0 0 0 0 0 0 0]\n [0 0 0 1 1 1 0 0]\n [0 0 0 1 0 1 0 0]]\n\n\nLayer 18:\n[[0 0 0 0 0 0 0 0]\n [0 0 0 0 0 0 0 0]\n [0 0 1 0 1 0 0 0]\n [0 0 0 1 0 1 0 0]\n [0 0 0 0 0 0 0 0]\n [1 1 1 1 1 1 1 1]\n [0 0 0 0 0 0 0 0]\n [0 0 0 0 0 0 0 0]]\n\n\nLayer 19:\n[[0 0 0 0 0 0 0 0]\n [0 0 0 0 0 0 0 0]\n [0 1 1 1 1 0 1 0]\n [0 0 0 1 0 1 0 1]\n [0 0 0 0 0 0 0 0]\n [1 0 1 0 0 0 0 0]\n [0 0 0 0 0 0 1 0]\n [0 0 0 0 0 0 0 0]]\n\n\nLayer 20:\n[[0 0 0 1 0 1 0 0]\n [0 0 0 1 1 1 0 0]\n [0 0 0 0 0 0 0 0]\n [0 0 0 0 0 0 0 0]\n [0 0 0 0 0 0 0 0]\n [0 0 0 0 0 0 0 0]\n [0 0 0 0 0 0 0 0]\n [0 0 0 0 0 0 0 0]]\n\n\nLayer 21:\n[[0 0 0 1 1 1 0 0]\n [0 0 0 1 0 1 0 0]\n [0 0 0 1 1 1 0 0]\n [0 0 1 0 0 0 0 0]\n [0 1 0 0 0 0 0 0]\n [0 0 0 0 0 0 0 0]\n [0 0 0 0 0 0 0 0]\n [0 0 0 0 0 0 0 0]]\n\n\nLayer 22:\n[[0 0 1 0 0 1 0 1]\n [0 1 0 0 0 0 0 0]\n [0 0 0 0 0 1 0 1]\n [0 1 0 0 0 0 0 0]\n [0 0 1 0 0 0 0 0]\n [0 0 0 1 0 0 0 0]\n [0 0 0 0 1 0 0 0]\n [0 0 0 0 0 0 0 0]]\n\n\nLayer 23:\n[[1 0 1 0 1 0 1 0]\n [0 0 0 1 0 0 0 1]\n [0 0 0 0 0 0 0 0]\n [0 0 0 1 0 0 0 1]\n [1 0 1 0 1 0 1 0]\n [0 0 0 0 0 0 0 0]\n [0 0 0 0 0 0 0 0]\n [0 0 0 0 0 0 0 0]]\n\n\nLayer 24:\n[[0 1 1 1 1 1 1 0]\n [1 0 0 0 0 0 0 1]\n [0 0 0 0 0 0 0 1]\n [0 0 0 0 0 0 0 1]\n [0 0 0 0 0 0 0 1]\n [0 0 0 0 0 0 0 1]\n [0 0 0 0 0 0 0 0]\n [0 0 0 0 0 0 0 0]]\n\n\nLayer 25:\n[[1 1 1 1 1 1 1 1]\n [1 1 1 1 1 1 1 1]\n [1 1 1 1 1 1 1 1]\n [1 1 1 1 1 1 1 1]\n [1 1 1 1 1 1 1 1]\n [1 1 1 1 1 1 1 1]\n [1 1 1 1 1 1 1 1]\n [1 1 1 1 1 1 1 1]]\n\n\nLayer 26:\n[[1 1 1 1 1 1 1 1]\n [1 1 1 1 1 1 1 1]\n [1 1 1 1 1 1 1 1]\n [1 1 1 1 1 1 1 1]\n [1 1 1 1 1 1 1 1]\n [1 1 1 1 1 1 1 1]\n [1 1 1 1 1 1 1 1]\n [1 1 1 1 1 1 1 1]]\n\n\nLayer 27:\n[[1 1 1 1 1 1 1 1]\n [1 1 1 1 1 1 1 1]\n [1 1 1 1 1 1 1 1]\n [1 1 1 1 1 1 1 1]\n [1 1 1 1 1 1 1 1]\n [1 1 1 1 1 1 1 1]\n [1 1 1 1 1 1 1 1]\n [1 1 1 1 1 1 1 1]]\n\n\nLayer 28:\n[[1 1 1 1 1 1 1 1]\n [1 1 1 1 1 1 1 1]\n [1 1 1 1 1 1 1 1]\n [1 1 1 1 1 1 1 1]\n [1 1 1 1 1 1 1 1]\n [1 1 1 1 1 1 1 1]\n [1 1 1 1 1 1 1 1]\n [1 1 1 1 1 1 1 1]]\n\n\n","output_type":"stream"}]},{"cell_type":"code","source":"def safe_sample(group, n):\n    return group.sample(n=n) if len(group) >= n else group\n\nbdf = df[df[\"Pieces\"] >= 5].groupby(\"Pieces\").apply(lambda x: safe_sample(x, 10000000)).reset_index(drop=True)\n\n# Áp dụng lại cho các nhóm \"Normalized WLD\"\nbbdf = bdf.groupby(\"Normalized WLD\").apply(lambda x: safe_sample(x, 2000000)).reset_index(drop=True)","metadata":{"execution":{"iopub.status.busy":"2024-05-25T13:55:12.141048Z","iopub.execute_input":"2024-05-25T13:55:12.141662Z","iopub.status.idle":"2024-05-25T13:55:27.252552Z","shell.execute_reply.started":"2024-05-25T13:55:12.141633Z","shell.execute_reply":"2024-05-25T13:55:27.251238Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"l = len(bbdf)\nbbdf = bbdf.sample(frac=1)\ntrain_df, test_df, cv_df = bbdf[:int(.8 * l)], bbdf[int(.8 * l): int(.9 * l)], bbdf[int(.9 * l):]","metadata":{"execution":{"iopub.status.busy":"2024-05-25T13:55:27.254410Z","iopub.execute_input":"2024-05-25T13:55:27.254721Z","iopub.status.idle":"2024-05-25T13:55:28.588619Z","shell.execute_reply.started":"2024-05-25T13:55:27.254694Z","shell.execute_reply":"2024-05-25T13:55:28.587573Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import gc\ngc.collect()","metadata":{"execution":{"iopub.status.busy":"2024-05-25T13:55:28.589986Z","iopub.execute_input":"2024-05-25T13:55:28.590409Z","iopub.status.idle":"2024-05-25T13:55:28.709927Z","shell.execute_reply.started":"2024-05-25T13:55:28.590372Z","shell.execute_reply":"2024-05-25T13:55:28.708801Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class ChessDataset(Dataset):\n    def __init__(self, df):\n        self.fens = torch.from_numpy(np.array([*map(to_bitboard, df[\"FEN\"])], dtype=np.uint8))\n        self.evals = torch.Tensor([[x] for x in df[\"Normalized Evaluation\"]])\n        self._len = len(self.evals)\n        \n    def __len__(self):\n        return self._len\n    \n    def __getitem__(self, index):\n        return self.fens[index], self.evals[index]\n\nd_train, d_test, d_cv = map(ChessDataset, [train_df, test_df, cv_df])","metadata":{"execution":{"iopub.status.busy":"2024-05-25T13:55:28.711977Z","iopub.execute_input":"2024-05-25T13:55:28.712529Z","iopub.status.idle":"2024-05-25T14:32:10.913827Z","shell.execute_reply.started":"2024-05-25T13:55:28.712495Z","shell.execute_reply":"2024-05-25T14:32:10.912989Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")","metadata":{"execution":{"iopub.status.busy":"2024-05-25T14:32:26.028171Z","iopub.execute_input":"2024-05-25T14:32:26.028720Z","iopub.status.idle":"2024-05-25T14:32:26.034061Z","shell.execute_reply.started":"2024-05-25T14:32:26.028681Z","shell.execute_reply":"2024-05-25T14:32:26.032977Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model = nn.Sequential(\n    nn.Conv2d(29, 128, kernel_size=3, padding=1),\n    nn.ReLU(),\n    nn.BatchNorm2d(128),\n    nn.Conv2d(128, 256, kernel_size=3, stride=1),\n    nn.ReLU(),\n    nn.BatchNorm2d(256),\n    nn.Dropout(0.4),\n    nn.Conv2d(256, 1024, kernel_size=2, stride=1),\n    nn.ReLU(),\n    nn.BatchNorm2d(1024),\n    nn.Dropout(0.4),\n    nn.Conv2d(1024, 512, kernel_size=2, stride=1),\n    nn.ReLU(),\n    nn.BatchNorm2d(512),\n    nn.Dropout(0.4),\n    nn.Conv2d(512, 256, kernel_size=3, stride=1),\n    nn.ReLU(),\n    nn.BatchNorm2d(256),\n    nn.Dropout(0.4),\n    nn.Flatten(),\n    nn.Linear(1024, 512),\n    nn.Dropout(0.2),\n    nn.Linear(512, 1) \n).to(device)\n\ndef init_weights(m):\n    try:\n        nn.init.xavier_uniform_(m.weight)\n        m.bias.data.fill_(0.01)\n    except Exception:\n        return\n\nmodel.apply(init_weights)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Đọc lại mảng từ file\ntrain_losses_read = np.loadtxt('/kaggle/input/no-check-mate-fen/train_losses.txt')\nval_losses_read = np.loadtxt('/kaggle/input/no-check-mate-fen/val_losses.txt')\n\n# Chuyển đổi mảng numpy thành list\ntrain_losses_read = train_losses_read.tolist()\nval_losses_read = val_losses_read.tolist()","metadata":{"execution":{"iopub.status.busy":"2024-05-25T14:40:54.799903Z","iopub.execute_input":"2024-05-25T14:40:54.800920Z","iopub.status.idle":"2024-05-25T14:40:54.807384Z","shell.execute_reply.started":"2024-05-25T14:40:54.800884Z","shell.execute_reply":"2024-05-25T14:40:54.806440Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#train_losses, val_losses = [], []\ntrain_losses = train_losses_read\nval_losses = val_losses_read\nprint(train_losses)\nprint(val_losses)\nbest_val_loss = 0.12899917476096856\nepoch_offset = 18\npatience = 10\ncounter = 1\ncheckpoint_path = 'best_model.pth'","metadata":{"execution":{"iopub.status.busy":"2024-05-25T14:56:41.742793Z","iopub.execute_input":"2024-05-25T14:56:41.743565Z","iopub.status.idle":"2024-05-25T14:56:41.748986Z","shell.execute_reply.started":"2024-05-25T14:56:41.743533Z","shell.execute_reply":"2024-05-25T14:56:41.747979Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model.load_state_dict(torch.load('/kaggle/input/no-check-mate-fen/best_model.pth'))","metadata":{"execution":{"iopub.status.busy":"2024-05-25T14:53:47.674625Z","iopub.execute_input":"2024-05-25T14:53:47.674992Z","iopub.status.idle":"2024-05-25T14:53:47.880254Z","shell.execute_reply.started":"2024-05-25T14:53:47.674963Z","shell.execute_reply":"2024-05-25T14:53:47.879347Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"batch_size = 128\nnum_work = 2\nprint(\"Converting to pytorch Dataset...\")\ntrain_loader = DataLoader(dataset=d_train, batch_size=batch_size, shuffle=True, num_workers=num_work)\ncv_loader = DataLoader(dataset=d_cv, batch_size=batch_size, shuffle=True, num_workers=num_work)\ncriterion = nn.MSELoss()\noptimizer = optim.AdamW(model.parameters(), lr=0.0003) \nprint(\"Done\")","metadata":{"execution":{"iopub.status.busy":"2024-05-25T14:54:55.688506Z","iopub.execute_input":"2024-05-25T14:54:55.689106Z","iopub.status.idle":"2024-05-25T14:54:55.696182Z","shell.execute_reply.started":"2024-05-25T14:54:55.689074Z","shell.execute_reply":"2024-05-25T14:54:55.695226Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# import time\n# import torch\n\n# train_losses, val_losses = [], []\n\n# best_val_loss = float('inf')\n# patience = 10\n# counter = 0\n# checkpoint_path = 'best_model.pth'\n\n# for epoch in range(1000):\n#     start_time = time.time()\n#     running_loss = []\n\n#     model.train()\n#     for data, target in train_loader:\n#         optimizer.zero_grad()\n#         data, target = data.to(device), target.to(device)\n#         y_pred = model(data.float())\n#         loss = criterion(y_pred, target)\n        \n#         running_loss.append(loss.item())\n#         loss.backward()\n#         optimizer.step()\n\n#     # Calculate average training loss for the epoch\n#     train_loss = sum(running_loss) / len(running_loss)\n#     train_losses.append(train_loss)\n\n#     # Print training loss for the epoch\n#     print(f\"[TRAIN] epoch: {epoch + 1:5}, loss: {train_loss:10}, time: {time.time() - start_time:.2f} seconds\", end=\"\\t\")\n\n#     # Validation loop\n#     model.eval()  # Set the model to eval mode\n#     running_loss = []\n#     with torch.no_grad():\n#         for data, target in cv_loader:\n#             data, target = data.to(device), target.to(device)\n#             y_pred = model(data.float())\n#             loss = criterion(y_pred, target)\n#             running_loss.append(loss.item())\n        \n#     # Calculate average validation loss for the epoch\n#     val_loss = sum(running_loss) / len(running_loss)\n#     val_losses.append(val_loss)\n\n#     # Print validation loss for the epoch\n#     print(f\"[VAL] epoch: {epoch + 1:5}, loss: {val_loss:10}, time: {time.time() - start_time:.2f} seconds\")\n\n#     # Check early stopping condition and save model if validation loss improves\n#     if val_loss < best_val_loss:\n#         best_val_loss = val_loss\n#         counter = 0\n#         torch.save(model.state_dict(), checkpoint_path)\n#         print(f\"Validation loss decreased ({val_loss:.6f}). Saving model ...\")\n#     else:\n#         counter += 1\n#         if counter >= patience:\n#             print(f\"Early stopping triggered at epoch {epoch + 1}\")\n#             break\n\n# print('Finished Training')\n# # Load the last checkpoint with the best model\n# model.load_state_dict(torch.load(checkpoint_path))\n# torch.save(model.state_dict(), 'final_model.pth')\n# print('Finished Training and Best Model Saved')","metadata":{"execution":{"iopub.status.busy":"2024-05-25T05:14:16.471697Z","iopub.execute_input":"2024-05-25T05:14:16.472107Z","iopub.status.idle":"2024-05-25T13:40:35.400977Z","shell.execute_reply.started":"2024-05-25T05:14:16.472079Z","shell.execute_reply":"2024-05-25T13:40:35.399060Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"for epoch in range(1000):\n    start_time = time.time()\n    running_loss = []\n\n    model.train()\n    for data, target in train_loader:\n        optimizer.zero_grad()\n        data, target = data.to(device), target.to(device)\n        y_pred = model(data.float())\n        loss = criterion(y_pred, target)\n        \n        running_loss.append(loss.item())\n        loss.backward()\n        optimizer.step()\n\n    # Calculate average training loss for the epoch\n    train_loss = sum(running_loss) / len(running_loss)\n    train_losses.append(train_loss)\n\n    # Print training loss for the epoch\n    print(f\"[TRAIN] epoch: {epoch + epoch_offset + 1 : 5}, loss: {train_loss:10}, time: {time.time() - start_time:.2f} seconds\", end=\"\\t\")\n\n    # Validation loop\n    model.eval()  # Set the model to eval mode\n    running_loss = []\n    with torch.no_grad():\n        for data, target in cv_loader:\n            data, target = data.to(device), target.to(device)\n            y_pred = model(data.float())\n            loss = criterion(y_pred, target)\n            running_loss.append(loss.item())\n        \n    # Calculate average validation loss for the epoch\n    val_loss = sum(running_loss) / len(running_loss)\n    val_losses.append(val_loss)\n\n    # Print validation loss for the epoch\n    print(f\"[VAL] epoch: {epoch + epoch_offset + 1:5}, loss: {val_loss:10}, time: {time.time() - start_time:.2f} seconds\")\n\n    # Check early stopping condition and save model if validation loss improves\n    if val_loss < best_val_loss:\n        best_val_loss = val_loss\n        counter = 0\n        torch.save(model.state_dict(), checkpoint_path)\n        print(f\"Validation loss decreased ({val_loss:.6f}). Saving model ...\")\n    else:\n        counter += 1\n        if counter >= patience:\n            print(f\"Early stopping triggered at epoch {epoch + epoch_offset + 1}\")\n            break\n\nprint('Finished Training')\n# Load the last checkpoint with the best model\nmodel.load_state_dict(torch.load(checkpoint_path))\ntorch.save(model.state_dict(), 'final_model.pth')\nprint('Finished Training and Best Model Saved')","metadata":{"execution":{"iopub.status.busy":"2024-05-25T15:00:21.490107Z","iopub.execute_input":"2024-05-25T15:00:21.490456Z","iopub.status.idle":"2024-05-25T20:26:53.206520Z","shell.execute_reply.started":"2024-05-25T15:00:21.490429Z","shell.execute_reply":"2024-05-25T20:26:53.205084Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Plotting the losses\nepochs = range(1, len(train_losses) + 1)\nplt.plot(epochs, train_losses, 'b', label='Training loss')\nplt.plot(epochs, val_losses, 'r', label='Validation loss')\nplt.title('Training and Validation Loss')\nplt.xlabel('Epochs')\nplt.ylabel('Loss')\nplt.legend()\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2024-05-25T20:27:00.840407Z","iopub.execute_input":"2024-05-25T20:27:00.840779Z","iopub.status.idle":"2024-05-25T20:27:01.156910Z","shell.execute_reply.started":"2024-05-25T20:27:00.840744Z","shell.execute_reply":"2024-05-25T20:27:01.156097Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import numpy as np\n\n# Chuyển đổi list thành mảng numpy\ntrain_losses_np = np.array(train_losses)\nval_losses_np = np.array(val_losses)\n\n# Lưu mảng vào file\nnp.savetxt('train_losses.txt', train_losses_np)\nnp.savetxt('val_losses.txt', val_losses_np)","metadata":{"execution":{"iopub.status.busy":"2024-05-25T20:27:14.558129Z","iopub.execute_input":"2024-05-25T20:27:14.559140Z","iopub.status.idle":"2024-05-25T20:27:14.565621Z","shell.execute_reply.started":"2024-05-25T20:27:14.559102Z","shell.execute_reply":"2024-05-25T20:27:14.564796Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import torch\nimport matplotlib.pyplot as plt\nfrom sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\nimport seaborn as sns\nfrom torch.utils.data import DataLoader, Subset\n\nnum_samples = 8000\nindices = list(range(num_samples))\nd_test_subset = Subset(d_test, indices)\ntest_loader = DataLoader(dataset=d_test_subset, batch_size=128, shuffle=False, num_workers=2)\n\n# Load the best model\nmodel.load_state_dict(torch.load(checkpoint_path))\nmodel.eval()\ndevice = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\nmodel.to(device)\n\n# Evaluate on test data\nrunning_loss = []\nall_preds = []\nall_labels = []\n\nwith torch.no_grad():\n    for data, target in test_loader:\n        data, target = data.to(device), target.to(device)\n        y_pred = model(data.float())\n        \n        loss = criterion(y_pred, target)\n        running_loss.append(loss.item())\n        \n        all_preds.extend(y_pred.cpu().numpy().flatten())\n        all_labels.extend(target.cpu().numpy().flatten())\n\n# Calculate average test loss\ntest_loss = sum(running_loss) / len(running_loss)\nprint(f\"[TEST] loss: {test_loss:10}\")\n\n# Calculate other regression metrics\nmse = mean_squared_error(all_labels, all_preds)\nmae = mean_absolute_error(all_labels, all_preds)\nr2 = r2_score(all_labels, all_preds)\n\nprint(f\"Mean Squared Error (MSE): {mse}\")\nprint(f\"Mean Absolute Error (MAE): {mae}\")\nprint(f\"R² Score: {r2}\")\n\n# Check the lengths of labels and predictions\nprint(f\"Length of all_labels: {len(all_labels)}\")\nprint(f\"Length of all_preds: {len(all_preds)}\")\n\n# Plot the results\nplt.figure(figsize=(10, 7))\nplt.scatter(all_labels, all_preds, alpha=0.3)\nplt.plot([min(all_labels), max(all_labels)], [min(all_labels), max(all_labels)], color='red', linestyle='--')\nplt.xlabel('Actual Values')\nplt.ylabel('Predicted Values')\nplt.title('Actual vs Predicted Values')\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2024-05-25T20:51:10.458575Z","iopub.execute_input":"2024-05-25T20:51:10.458974Z","iopub.status.idle":"2024-05-25T20:51:12.767299Z","shell.execute_reply.started":"2024-05-25T20:51:10.458942Z","shell.execute_reply":"2024-05-25T20:51:12.766269Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import numpy as np\n\nnp.savez('predictions.npz', labels=all_labels, predictions=all_preds)","metadata":{"execution":{"iopub.status.busy":"2024-05-25T20:55:27.197259Z","iopub.execute_input":"2024-05-25T20:55:27.197762Z","iopub.status.idle":"2024-05-25T20:55:27.205555Z","shell.execute_reply.started":"2024-05-25T20:55:27.197724Z","shell.execute_reply":"2024-05-25T20:55:27.204622Z"},"trusted":true},"execution_count":null,"outputs":[]}]}